{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport itertools\nimport time\nimport random\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.colors as mcolors\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim import AdamW\nfrom torch.optim.lr_scheduler import (CosineAnnealingLR,\n                                      CosineAnnealingWarmRestarts,\n                                      StepLR,\n                                      ExponentialLR)\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import accuracy_score, auc, f1_score, precision_score, recall_score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    csv_path = ''\n    seed = 2021\n    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n    attn_state_path = '../input/mitbih-with-synthetic/attn.pth'\n    lstm_state_path = '../input/mitbih-with-synthetic/lstm.pth'\n    cnn_state_path = '../input/mitbih-with-synthetic/cnn.pth'\n    \n    attn_logs = '../input/mitbih-with-synthetic/attn.csv'\n    lstm_logs = '../input/mitbih-with-synthetic/lstm.csv'\n    cnn_logs = '../input/mitbih-with-synthetic/cnn.csv'\n    \n    train_csv_path = '../input/mitbih-with-synthetic/mitbih_with_syntetic_train.csv'\n    test_csv_path = '../input/mitbih-with-synthetic/mitbih_with_syntetic_test.csv'\n\ndef seed_everything(seed: int):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\nconfig = Config()\nseed_everything(config.seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_ptbdb = pd.read_csv('/kaggle/input/heartbeat/ptbdb_abnormal.csv')\ndf_mitbih = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv')\ndf_ptbdb","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mitbih_train = pd.read_csv('/kaggle/input/heartbeat/mitbih_train.csv', header=None)\ndf_mitbih_test = pd.read_csv('/kaggle/input/heartbeat/mitbih_test.csv', header=None)\ndf_mitbih = pd.concat([df_mitbih_train, df_mitbih_test], axis=0)\ndf_mitbih.rename(columns={187: 'class'}, inplace=True)\n\nid_to_label = {\n    0: \"Normal\",\n    1: \"Artial Premature\",\n    2: \"Premature ventricular contraction\",\n    3: \"Fusion of ventricular and normal\",\n    4: \"Fusion of paced and normal\"\n}\ndf_mitbih['label'] = df_mitbih.iloc[:, -1].map(id_to_label)\nprint(df_mitbih.info())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_mitbih.to_csv('data.csv', index=False)\nconfig.csv_path = 'data.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Basic EDA","metadata":{}},{"cell_type":"code","source":"df_mitbih = pd.read_csv(config.csv_path)\ndf_mitbih['label'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentages = [count / df_mitbih.shape[0] * 100 for count in df_mitbih['label'].value_counts()]\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.countplot(\n    x=df_mitbih['label'],\n    ax=ax,\n    palette=\"bright\",\n    order=df_mitbih['label'].value_counts().index\n)\nax.set_xticklabels(ax.get_xticklabels(), rotation=15);\n\nfor percentage, count, p in zip(\n    percentages,\n    df_mitbih['label'].value_counts(sort=True).values,\n    ax.patches):\n    \n    percentage = f'{np.round(percentage, 2)}%'\n    x = p.get_x() + p.get_width() / 2 - 0.4\n    y = p.get_y() + p.get_height()\n    ax.annotate(str(percentage)+\" / \"+str(count), (x, y), fontsize=12, fontweight='bold')\n    \nplt.savefig('data_dist.png', facecolor='w', edgecolor='w', format='png',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)\nplt.savefig('data_dist.svg', facecolor='w', edgecolor='w', format='svg',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I used the GAN from the notebook you can find [here](https://www.kaggle.com/polomarco/1d-gan-for-ecg-synthesis) or a repository with the code [here](https://github.com/mandrakedrink/ECG-Synthesis-and-Classification) to generate new synthetic data for classes with little data, now the dataset looks like this:","metadata":{}},{"cell_type":"code","source":"config.csv_path = '../input/mitbih-with-synthetic/mitbih_with_syntetic.csv'\ndf_mitbih_new = pd.read_csv(config.csv_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"percentages1 = [count / df_mitbih.shape[0] * 100 for count in df_mitbih['label'].value_counts()]\npercentages2 = [count / df_mitbih_new.shape[0] * 100 for count in df_mitbih_new['label'].value_counts()]\n\nfig, axs = plt.subplots(1,2, figsize=(18, 4))\n\n# origin\nsns.countplot(\n    x=df_mitbih['label'],\n    ax=axs[0],\n    palette=\"bright\",\n    order=df_mitbih['label'].value_counts().index\n)\naxs[0].set_xticklabels(axs[0].get_xticklabels(), rotation=15);\naxs[0].set_title(\"Before\", fontsize=15)\n\nfor percentage, count, p in zip(\n    percentages1,\n    df_mitbih['label'].value_counts(sort=True).values,\n    axs[0].patches):\n    \n    percentage = f'{np.round(percentage, 2)}%'\n    x = p.get_x() + p.get_width() / 2 - 0.4\n    y = p.get_y() + p.get_height()\n    axs[0].annotate(str(percentage)+\" / \"+str(count), (x, y), fontsize=10, fontweight='bold')\n\n# with synthetic\nsns.countplot(\n    x=df_mitbih_new['label'],\n    ax=axs[1],\n    palette=\"bright\",\n    order=df_mitbih_new['label'].value_counts().index\n)\naxs[1].set_xticklabels(axs[1].get_xticklabels(), rotation=15);\naxs[1].set_title(\"After\", fontsize=15)\n\nfor percentage, count, p in zip(\n    percentages2,\n    df_mitbih_new['label'].value_counts(sort=True).values,\n    axs[1].patches):\n    \n    percentage = f'{np.round(percentage, 2)}%'\n    x = p.get_x() + p.get_width() / 2 - 0.4\n    y = p.get_y() + p.get_height()\n    axs[1].annotate(str(percentage)+\" / \"+str(count), (x, y), fontsize=10, fontweight='bold')\n\n#plt.suptitle(\"Balanced Sampling between classes\", fontsize=20, weight=\"bold\", y=1.01)\nplt.savefig('data_dist.png', facecolor='w', edgecolor='w', format='png',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)\nplt.savefig('data_dist.svg', facecolor='w', edgecolor='w', format='svg',\n        transparent=False, bbox_inches='tight', pad_inches=0.1)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = 5\nsamples = [df_mitbih.loc[df_mitbih['class'] == cls].sample(N) for cls in range(N)]\ntitles = [id_to_label[cls] for cls in range(5)]\n\nwith plt.style.context(\"seaborn-white\"):\n    fig, axs = plt.subplots(3, 2, figsize=(20, 7))\n    for i in range(5):\n        ax = axs.flat[i]\n        ax.plot(samples[i].values[:,:-2].transpose())\n        ax.set_title(titles[i])\n        #plt.ylabel(\"Amplitude\")\n\n    plt.tight_layout()\n    plt.suptitle(\"ECG Signals\", fontsize=20, y=1.05, weight=\"bold\")\n    plt.savefig(f\"signals_per_class.svg\",\n                    format=\"svg\",bbox_inches='tight', pad_inches=0.2)\n        \n    plt.savefig(f\"signals_per_class.png\", \n                    format=\"png\",bbox_inches='tight', pad_inches=0.2) ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsignals = [' '.join(df_mitbih.iloc[i, :-1].apply(str).values) for i in range(df_mitbih.shape[0])]\ny = df_mitbih.iloc[:, -1].values.tolist()\nprint(len(signals), len(y))\n\nprint(f'data has {len(set([sig for line in signals for sig in line.split()]))} out of 16 372 411 unique values.')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"class ECGDataset(Dataset):\n\n    def __init__(self, df):\n        self.df = df\n        self.data_columns = self.df.columns[:-2].tolist()\n\n    def __getitem__(self, idx):\n        signal = self.df.loc[idx, self.data_columns].astype('float32')\n        signal = torch.FloatTensor([signal.values])                 \n        target = torch.LongTensor(np.array(self.df.loc[idx, 'class']))\n        return signal, target\n\n    def __len__(self):\n        return len(self.df)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloader(phase: str, batch_size: int = 96) -> DataLoader:\n    '''\n    Dataset and DataLoader.\n    Parameters:\n        pahse: training or validation phase.\n        batch_size: data per iteration.\n    Returns:\n        data generator\n    '''\n    df = pd.read_csv(config.train_csv_path)\n    train_df, val_df = train_test_split(\n        df, test_size=0.15, random_state=config.seed, stratify=df['label']\n    )\n    train_df, val_df = train_df.reset_index(drop=True), val_df.reset_index(drop=True)\n    df = train_df if phase == 'train' else val_df\n    dataset = ECGDataset(df)\n    dataloader = DataLoader(dataset=dataset, batch_size=batch_size, num_workers=4)\n    return dataloader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models","metadata":{}},{"cell_type":"markdown","source":"![](https://64.media.tumblr.com/e42e20eb2ec1aea3962c6ace63adf499/70877119c7741403-44/s540x810/c8f722eb2ab3d92c98070554db4815ca8c01510b.png)","metadata":{}},{"cell_type":"code","source":"class Swish(nn.Module):\n    def forward(self, x):\n        return x * torch.sigmoid(x)\n    \nx = torch.linspace(-10.0, 10.0, 100)\nswish = Swish()\nswish_out = swish(x)\nrelu_out = torch.relu(x)\n\nplt.title('Swish function')\nplt.plot(x.numpy(), swish_out.numpy(), label='Swish')\nplt.plot(x.numpy(), relu_out.numpy(), label='ReLU')\nplt.legend();\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvNormPool(nn.Module):\n    \"\"\"Conv Skip-connection module\"\"\"\n    def __init__(\n        self,\n        input_size,\n        hidden_size,\n        kernel_size,\n        norm_type='bachnorm'\n    ):\n        super().__init__()\n        \n        self.kernel_size = kernel_size\n        self.conv_1 = nn.Conv1d(\n            in_channels=input_size,\n            out_channels=hidden_size,\n            kernel_size=kernel_size\n        )\n        self.conv_2 = nn.Conv1d(\n            in_channels=hidden_size,\n            out_channels=hidden_size,\n            kernel_size=kernel_size\n        )\n        self.conv_3 = nn.Conv1d(\n            in_channels=hidden_size,\n            out_channels=hidden_size,\n            kernel_size=kernel_size\n        )\n        self.swish_1 = Swish()\n        self.swish_2 = Swish()\n        self.swish_3 = Swish()\n        if norm_type == 'group':\n            self.normalization_1 = nn.GroupNorm(\n                num_groups=8,\n                num_channels=hidden_size\n            )\n            self.normalization_2 = nn.GroupNorm(\n                num_groups=8,\n                num_channels=hidden_size\n            )\n            self.normalization_3 = nn.GroupNorm(\n                num_groups=8,\n                num_channels=hidden_size\n            )\n        else:\n            self.normalization_1 = nn.BatchNorm1d(num_features=hidden_size)\n            self.normalization_2 = nn.BatchNorm1d(num_features=hidden_size)\n            self.normalization_3 = nn.BatchNorm1d(num_features=hidden_size)\n            \n        self.pool = nn.MaxPool1d(kernel_size=2)\n        \n    def forward(self, input):\n        conv1 = self.conv_1(input)\n        x = self.normalization_1(conv1)\n        x = self.swish_1(x)\n        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n        \n        x = self.conv_2(x)\n        x = self.normalization_2(x)\n        x = self.swish_2(x)\n        x = F.pad(x, pad=(self.kernel_size - 1, 0))\n        \n        conv3 = self.conv_3(x)\n        x = self.normalization_3(conv1+conv3)\n        x = self.swish_3(x)\n        x = F.pad(x, pad=(self.kernel_size - 1, 0))   \n        \n        x = self.pool(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(\n        self,\n        input_size = 1,\n        hid_size = 256,\n        kernel_size = 5,\n        num_classes = 5,\n    ):\n        \n        super().__init__()\n        \n        self.conv1 = ConvNormPool(\n            input_size=input_size,\n            hidden_size=hid_size,\n            kernel_size=kernel_size,\n        )\n        self.conv2 = ConvNormPool(\n            input_size=hid_size,\n            hidden_size=hid_size//2,\n            kernel_size=kernel_size,\n        )\n        self.conv3 = ConvNormPool(\n            input_size=hid_size//2,\n            hidden_size=hid_size//4,\n            kernel_size=kernel_size,\n        )\n        self.avgpool = nn.AdaptiveAvgPool1d((1))\n        self.fc = nn.Linear(in_features=hid_size//4, out_features=num_classes)\n        \n    def forward(self, input):\n        x = self.conv1(input)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.avgpool(x)        \n        # print(x.shape) # num_features * num_channels\n        x = x.view(-1, x.size(1) * x.size(2))\n        x = F.softmax(self.fc(x), dim=1)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNN(nn.Module):\n    \"\"\"RNN module(cell type lstm or gru)\"\"\"\n    def __init__(\n        self,\n        input_size,\n        hid_size,\n        num_rnn_layers=1,\n        dropout_p = 0.2,\n        bidirectional = False,\n        rnn_type = 'lstm',\n    ):\n        super().__init__()\n        \n        if rnn_type == 'lstm':\n            self.rnn_layer = nn.LSTM(\n                input_size=input_size,\n                hidden_size=hid_size,\n                num_layers=num_rnn_layers,\n                dropout=dropout_p if num_rnn_layers>1 else 0,\n                bidirectional=bidirectional,\n                batch_first=True,\n            )\n            \n        else:\n            self.rnn_layer = nn.GRU(\n                input_size=input_size,\n                hidden_size=hid_size,\n                num_layers=num_rnn_layers,\n                dropout=dropout_p if num_rnn_layers>1 else 0,\n                bidirectional=bidirectional,\n                batch_first=True,\n            )\n    def forward(self, input):\n        outputs, hidden_states = self.rnn_layer(input)\n        return outputs, hidden_states","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RNNModel(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        hid_size,\n        rnn_type,\n        bidirectional,\n        n_classes=5,\n        kernel_size=5,\n    ):\n        super().__init__()\n            \n        self.rnn_layer = RNN(\n            input_size=46,#hid_size * 2 if bidirectional else hid_size,\n            hid_size=hid_size,\n            rnn_type=rnn_type,\n            bidirectional=bidirectional\n        )\n        self.conv1 = ConvNormPool(\n            input_size=input_size,\n            hidden_size=hid_size,\n            kernel_size=kernel_size,\n        )\n        self.conv2 = ConvNormPool(\n            input_size=hid_size,\n            hidden_size=hid_size,\n            kernel_size=kernel_size,\n        )\n        self.avgpool = nn.AdaptiveAvgPool1d((1))\n        self.fc = nn.Linear(in_features=hid_size, out_features=n_classes)\n\n    def forward(self, input):\n        x = self.conv1(input)\n        x = self.conv2(x)\n        x, _ = self.rnn_layer(x)\n        x = self.avgpool(x)\n        x = x.view(-1, x.size(1) * x.size(2))\n        x = F.softmax(self.fc(x), dim=1)#.squeeze(1)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### \"Attention Mechanism\" Quick Reminder\n\n\nThe attention mechanism is best explained with the example of the seq2seq model, so it would be a great idea to read this interactive [article](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html).\n\nModels based an architecture such as sequence2sequence, for example, to translate from one language to another, **Attention**, use to clarify the word order, when translating by the decoder, more specificaly to make weights of some words more or less meaningful in the encoder path, for improved translation.\n\n\n### Excerpt from [article](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html):\nAt each decoder step, attention:\n+ receives attention input: a decoder state ht and all encoder states s1, s2...sk;\n+ computes attention scores;\n+ For each encoder state sk attention computes its \"relevance\" for this decoder state ht. Formally, it applies an attention function which receives one decoder state and one encoder state and returns a scalar value **score(ht, sk)**;\n+ computes attention weights: a probability distribution - softmax applied to attention scores;\n+ computes attention output: the weighted sum of encoder states with attention weights.\n    \nThe general computation scheme is shown below.\n<img src=\"https://lena-voita.github.io/resources/lectures/seq2seq/attention/computation_scheme-min.png\" alt=\"drawing\" width=\"60%\" height=\"60%\"/>\n\nThe most popular ways to compute attention scores are:\n\n+ dot-product - the simplest method;\n+ bilinear function (aka \"Luong attention\") - used in the paper Effective Approaches to Attention-based Neural Machine Translation;\n+ multi-layer perceptron (aka \"Bahdanau attention\") - the method proposed in the original paper.\n![alt](https://lena-voita.github.io/resources/lectures/seq2seq/attention/score_functions-min.png)\n\n---\n\nWe will use Attention mechanism in ecg classification, \"to clarify\" to give more attention to important features, be it features from recurrent layers or convolutional.","metadata":{}},{"cell_type":"code","source":"class RNNAttentionModel(nn.Module):\n    def __init__(\n        self,\n        input_size,\n        hid_size,\n        rnn_type,\n        bidirectional,\n        n_classes=5,\n        kernel_size=5,\n    ):\n        super().__init__()\n \n        self.rnn_layer = RNN(\n            input_size=46,\n            hid_size=hid_size,\n            rnn_type=rnn_type,\n            bidirectional=bidirectional\n        )\n        self.conv1 = ConvNormPool(\n            input_size=input_size,\n            hidden_size=hid_size,\n            kernel_size=kernel_size,\n        )\n        self.conv2 = ConvNormPool(\n            input_size=hid_size,\n            hidden_size=hid_size,\n            kernel_size=kernel_size,\n        )\n        self.avgpool = nn.AdaptiveMaxPool1d((1))\n        self.attn = nn.Linear(hid_size, hid_size, bias=False)\n        self.fc = nn.Linear(in_features=hid_size, out_features=n_classes)\n        \n    def forward(self, input):\n        x = self.conv1(input)\n        x = self.conv2(x)\n        x_out, hid_states = self.rnn_layer(x)\n        x = torch.cat([hid_states[0], hid_states[1]], dim=0).transpose(0, 1)\n        x_attn = torch.tanh(self.attn(x))\n        x = x_attn.bmm(x_out)\n        x = x.transpose(2, 1)\n        x = self.avgpool(x)\n        x = x.view(-1, x.size(1) * x.size(2))\n        x = F.softmax(self.fc(x), dim=-1)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Stage","metadata":{}},{"cell_type":"code","source":"class Meter:\n    def __init__(self, n_classes=5):\n        self.metrics = {}\n        self.confusion = torch.zeros((n_classes, n_classes))\n    \n    def update(self, x, y, loss):\n        x = np.argmax(x.detach().cpu().numpy(), axis=1)\n        y = y.detach().cpu().numpy()\n        self.metrics['loss'] += loss\n        self.metrics['accuracy'] += accuracy_score(x,y)\n        self.metrics['f1'] += f1_score(x,y,average='macro')\n        self.metrics['precision'] += precision_score(x, y, average='macro', zero_division=1)\n        self.metrics['recall'] += recall_score(x,y, average='macro', zero_division=1)\n        \n        self._compute_cm(x, y)\n        \n    def _compute_cm(self, x, y):\n        for prob, target in zip(x, y):\n            if prob == target:\n                self.confusion[target][target] += 1\n            else:\n                self.confusion[target][prob] += 1\n    \n    def init_metrics(self):\n        self.metrics['loss'] = 0\n        self.metrics['accuracy'] = 0\n        self.metrics['f1'] = 0\n        self.metrics['precision'] = 0\n        self.metrics['recall'] = 0\n        \n    def get_metrics(self):\n        return self.metrics\n    \n    def get_confusion_matrix(self):\n        return self.confusion","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, net, lr, batch_size, num_epochs):\n        self.net = net.to(config.device)\n        self.num_epochs = num_epochs\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = AdamW(self.net.parameters(), lr=lr)\n        self.scheduler = CosineAnnealingLR(self.optimizer, T_max=num_epochs, eta_min=5e-6)\n        self.best_loss = float('inf')\n        self.phases = ['train', 'val']\n        self.dataloaders = {\n            phase: get_dataloader(phase, batch_size) for phase in self.phases\n        }\n        self.train_df_logs = pd.DataFrame()\n        self.val_df_logs = pd.DataFrame()\n    \n    def _train_epoch(self, phase):\n        print(f\"{phase} mode | time: {time.strftime('%H:%M:%S')}\")\n        \n        self.net.train() if phase == 'train' else self.net.eval()\n        meter = Meter()\n        meter.init_metrics()\n        \n        for i, (data, target) in enumerate(self.dataloaders[phase]):\n            data = data.to(config.device)\n            target = target.to(config.device)\n            \n            output = self.net(data)\n            loss = self.criterion(output, target)\n                        \n            if phase == 'train':\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n            \n            meter.update(output, target, loss.item())\n        \n        metrics = meter.get_metrics()\n        metrics = {k:v / i for k, v in metrics.items()}\n        df_logs = pd.DataFrame([metrics])\n        confusion_matrix = meter.get_confusion_matrix()\n        \n        if phase == 'train':\n            self.train_df_logs = pd.concat([self.train_df_logs, df_logs], axis=0)\n        else:\n            self.val_df_logs = pd.concat([self.val_df_logs, df_logs], axis=0)\n        \n        # show logs\n        print('{}: {}, {}: {}, {}: {}, {}: {}, {}: {}'\n              .format(*(x for kv in metrics.items() for x in kv))\n             )\n        fig, ax = plt.subplots(figsize=(5, 5))\n        cm_ = ax.imshow(confusion_matrix, cmap='hot')\n        ax.set_title('Confusion matrix', fontsize=15)\n        ax.set_xlabel('Actual', fontsize=13)\n        ax.set_ylabel('Predicted', fontsize=13)\n        plt.colorbar(cm_)\n        plt.show()\n        \n        return loss\n    \n    def run(self):\n        for epoch in range(self.num_epochs):\n            self._train_epoch(phase='train')\n            with torch.no_grad():\n                val_loss = self._train_epoch(phase='val')\n                self.scheduler.step()\n            \n            if val_loss < self.best_loss:\n                self.best_loss = val_loss\n                print('\\nNew checkpoint\\n')\n                self.best_loss = val_loss\n                torch.save(self.net.state_dict(), f\"best_model_epoc{epoch}.pth\")\n            #clear_output()\n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = RNNAttentionModel(1, 64, 'lstm', False)\n#model = RNNModel(1, 64, 'lstm', True)\nmodel = CNN(num_classes=5, hid_size=128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = Trainer(net=model, lr=1e-3, batch_size=96, num_epochs=10)#100)\ntrainer.run()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_logs = trainer.train_df_logs\ntrain_logs.columns = [\"train_\"+ colname for colname in train_logs.columns]\nval_logs = trainer.val_df_logs\nval_logs.columns = [\"val_\"+ colname for colname in val_logs.columns]\n\nlogs = pd.concat([train_logs,val_logs], axis=1)\nlogs.reset_index(drop=True, inplace=True)\nlogs = logs.loc[:, [\n    'train_loss', 'val_loss', \n    'train_accuracy', 'val_accuracy', \n    'train_f1', 'val_f1',\n    'train_precision', 'val_precision',\n    'train_recall', 'val_recall']\n                                 ]\nlogs.head()\nlogs.to_csv('cnn.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiments and Results","metadata":{}},{"cell_type":"code","source":"cnn_model = CNN(num_classes=5, hid_size=128).to(config.device)\ncnn_model.load_state_dict(\n    torch.load(config.cnn_state_path,\n               map_location=config.device)\n);\ncnn_model.eval();\nlogs = pd.read_csv(config.cnn_logs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#C042FF', '#03C576FF', '#FF355A', '#03C5BF', '#96C503', '#C5035B']\npalettes = [sns.color_palette(colors, 2),\n            sns.color_palette(colors, 4), \n            sns.color_palette(colors[:2]+colors[-2:] + colors[2:-2], 6)]\n            \nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.lineplot(data=logs.iloc[:, :2], palette=palettes[0], markers=True, ax=ax[0], linewidth=2.5,)\nax[0].set_title(\"Loss Function during Model Training\", fontsize=14)\nax[0].set_xlabel(\"Epoch\", fontsize=14)\n\nsns.lineplot(data=logs.iloc[:, 2:6], palette=palettes[1], markers=True, ax=ax[1], linewidth=2.5, legend=\"full\")\nax[1].set_title(\"Metrics during Model Training\", fontsize=15)\nax[1].set_xlabel(\"Epoch\", fontsize=14)\n\nplt.suptitle('CNN Model', fontsize=18)\n\nplt.tight_layout()\nfig.savefig(\"cnn.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nfig.savefig(\"cnn.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lstm_model = RNNModel(1, 64, 'lstm', True).to(config.device)\nlstm_model.load_state_dict(\n    torch.load(config.lstm_state_path,\n               map_location=config.device)\n);\nlstm_model.eval();\nlogs = pd.read_csv(config.lstm_logs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#C042FF', '#03C576FF', '#FF355A', '#03C5BF', '#96C503', '#C5035B']\npalettes = [sns.color_palette(colors, 2),\n            sns.color_palette(colors, 4), \n            sns.color_palette(colors[:2]+colors[-2:] + colors[2:-2], 6)]\n            \nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.lineplot(data=logs.iloc[:, :2], palette=palettes[0], markers=True, ax=ax[0], linewidth=2.5,)\nax[0].set_title(\"Loss Function during Model Training\", fontsize=14)\nax[0].set_xlabel(\"Epoch\", fontsize=14)\n\nsns.lineplot(data=logs.iloc[:, 2:6], palette=palettes[1], markers=True, ax=ax[1], linewidth=2.5, legend=\"full\")\nax[1].set_title(\"Metrics during Model Training\", fontsize=15)\nax[1].set_xlabel(\"Epoch\", fontsize=14)\n\nplt.suptitle('CNN+LSTM Model', fontsize=18)\n\nplt.tight_layout()\nfig.savefig(\"lstm.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nfig.savefig(\"lstm.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attn_model = RNNAttentionModel(1, 64, 'lstm', False).to(config.device)\nattn_model.load_state_dict(\n    torch.load(config.attn_state_path,\n               map_location=config.device)\n);\nattn_model.eval();\nlogs = pd.read_csv(config.attn_logs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#C042FF', '#03C576FF', '#FF355A', '#03C5BF', '#96C503', '#C5035B']\npalettes = [sns.color_palette(colors, 2),\n            sns.color_palette(colors, 4), \n            sns.color_palette(colors[:2]+colors[-2:] + colors[2:-2], 6)]\n            \nfig, ax = plt.subplots(1, 2, figsize=(12, 4))\n\nsns.lineplot(data=logs.iloc[:, :2], palette=palettes[0], markers=True, ax=ax[0], linewidth=2.5,)\nax[0].set_title(\"Loss Function during Model Training\", fontsize=14)\nax[0].set_xlabel(\"Epoch\", fontsize=14)\n\nsns.lineplot(data=logs.iloc[:, 2:6], palette=palettes[1], markers=True, ax=ax[1], linewidth=2.5, legend=\"full\")\nax[1].set_title(\"Metrics during Model Training\", fontsize=15)\nax[1].set_xlabel(\"Epoch\", fontsize=14)\n\nplt.suptitle('CNN+LSTM+Attention Model', fontsize=18)\n\nplt.tight_layout()\nfig.savefig(\"attn.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nfig.savefig(\"attn.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Experiments and Results for Test Stage","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv(config.test_csv_path)\nprint(test_df.shape)\ntest_dataset = ECGDataset(test_df)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=96, num_workers=0, shuffle=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_stage(dataloader, model, probs=False):\n    cls_predictions = []\n    cls_ground_truths = []\n\n    for i, (data, cls_target) in enumerate(dataloader):\n        with torch.no_grad():\n\n            data = data.to(config.device)\n            cls_target = cls_target.cpu()\n            cls_prediction = model(data)\n            \n            if not probs:\n                cls_prediction = torch.argmax(cls_prediction, dim=1)\n    \n            cls_predictions.append(cls_prediction.detach().cpu())\n            cls_ground_truths.append(cls_target)\n\n    predictions_cls = torch.cat(cls_predictions).numpy()\n    ground_truths_cls = torch.cat(cls_ground_truths).numpy()\n    return predictions_cls, ground_truths_cls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = [cnn_model, lstm_model, attn_model]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### cnn model report","metadata":{}},{"cell_type":"code","source":"y_pred, y_true = make_test_stage(test_dataloader, models[0])\ny_pred.shape, y_true.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = pd.DataFrame(\n    classification_report(\n        y_pred,\n        y_true,\n        output_dict=True\n    )\n).transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#00FA9A', '#D2B48C', '#FF69B4']#random.choices(list(mcolors.CSS4_COLORS.values()), k = 3)\nreport_plot = report.apply(lambda x: x*100)\nax = report_plot[[\"precision\", \"recall\", \"f1-score\"]].plot(kind='bar',\n                                                      figsize=(13, 4), legend=True, fontsize=15, color=colors)\n\nax.set_xlabel(\"Estimators\", fontsize=15)\nax.set_xticklabels(\n    list(id_to_label.values())+[\"accuracy avg\", \"marco avg\", \"weighted avg\"],\n    rotation=15, fontsize=11)\nax.set_ylabel(\"Percentage\", fontsize=15)\nplt.title(\"CNN Model Classification Report\", fontsize=20)\n\nfor percentage, p in zip(\n    report[['precision', 'recall', 'f1-score']].values,\n    ax.patches):\n    \n    percentage = \" \".join([str(round(i*100, 2))+\"%\" for i in percentage])\n    x = p.get_x() + p.get_width() - 0.4\n    y = p.get_y() + p.get_height() / 4\n    ax.annotate(percentage, (x, y), fontsize=8, rotation=15, fontweight='bold')\nfig.savefig(\"cnn_report.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nfig.savefig(\"cnn_report.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### cnn+lstm model report","metadata":{}},{"cell_type":"code","source":"y_pred, y_true = make_test_stage(test_dataloader, models[1])\ny_pred.shape, y_true.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = pd.DataFrame(\n    classification_report(\n        y_pred,\n        y_true,\n        output_dict=True\n    )\n).transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#00FA9A', '#D2B48C', '#FF69B4']#random.choices(list(mcolors.CSS4_COLORS.values()), k = 3)\nreport_plot = report.apply(lambda x: x*100)\nax = report_plot[[\"precision\", \"recall\", \"f1-score\"]].plot(kind='bar',\n                                                      figsize=(13, 4), legend=True, fontsize=15, color=colors)\n\nax.set_xlabel(\"Estimators\", fontsize=15)\nax.set_xticklabels(\n    list(id_to_label.values())+[\"accuracy avg\", \"marco avg\", \"weighted avg\"],\n    rotation=15, fontsize=11)\nax.set_ylabel(\"Percentage\", fontsize=15)\nplt.title(\"CNN+LSTM Model Classification Report\", fontsize=20)\n\nfor percentage, p in zip(\n    report[['precision', 'recall', 'f1-score']].values,\n    ax.patches):\n    \n    percentage = \" \".join([str(round(i*100, 2))+\"%\" for i in percentage])\n    x = p.get_x() + p.get_width() - 0.4\n    y = p.get_y() + p.get_height() / 4\n    ax.annotate(percentage, (x, y), fontsize=8, rotation=15, fontweight='bold')\nfig.savefig(\"lstm_report.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nfig.savefig(\"lstm_report.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### cnn+lstm+attention model report","metadata":{}},{"cell_type":"code","source":"y_pred, y_true = make_test_stage(test_dataloader, models[2])\ny_pred.shape, y_true.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"report = pd.DataFrame(\n    classification_report(\n        y_pred,\n        y_true,\n        output_dict=True\n    )\n).transpose()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = ['#00FA9A', '#D2B48C', '#FF69B4']#random.choices(list(mcolors.CSS4_COLORS.values()), k = 3)\nreport_plot = report.apply(lambda x: x*100)\nax = report_plot[[\"precision\", \"recall\", \"f1-score\"]].plot(kind='bar',\n                                                      figsize=(13, 4), legend=True, fontsize=15, color=colors)\n\nax.set_xlabel(\"Estimators\", fontsize=15)\nax.set_xticklabels(\n    list(id_to_label.values())+[\"accuracy avg\", \"marco avg\", \"weighted avg\"],\n    rotation=15, fontsize=11)\nax.set_ylabel(\"Percentage\", fontsize=15)\nplt.title(\"CNN+LSTM+Attention Model Classification Report\", fontsize=20)\n\nfor percentage, p in zip(\n    report[['precision', 'recall', 'f1-score']].values,\n    ax.patches):\n    \n    percentage = \" \".join([str(round(i*100, 2))+\"%\" for i in percentage])\n    x = p.get_x() + p.get_width() - 0.4\n    y = p.get_y() + p.get_height() / 4\n    ax.annotate(percentage, (x, y), fontsize=8, rotation=15, fontweight='bold')\nfig.savefig(\"attn_report.png\", format=\"png\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nfig.savefig(\"attn_report.svg\", format=\"svg\",  pad_inches=0.2, transparent=False, bbox_inches='tight')\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ensemble of all models","metadata":{}},{"cell_type":"code","source":"y_pred = np.zeros((y_pred.shape[0], 5), dtype=np.float32)\nfor i, model in enumerate(models, 1):\n    y_pred_, y_true = make_test_stage(test_dataloader, model, True)\n    y_pred += y_pred_\ny_pred /= i\ny_pred = np.argmax(y_pred, axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_report = classification_report(y_pred, \n                                   y_true,\n                                   labels=[0,1,2,3,4],\n                                   target_names=list(id_to_label.values()),#['N', 'S', 'V', 'F', 'Q'],\n                                   output_dict=True)\n\n\nplt.figure(figsize=(10, 8))\nax = sns.heatmap(pd.DataFrame(clf_report).iloc[:-1, :].T, annot=True)\nax.set_xticklabels(ax.get_xticklabels(),fontsize=15)\nax.set_yticklabels(ax.get_yticklabels(),fontsize=12, rotation=0)\nplt.title(\"Ensemble Classification Report\", fontsize=20)\nplt.savefig(f\"ensemble result.svg\",format=\"svg\",bbox_inches='tight', pad_inches=0.2)\nplt.savefig(f\"ensemble result.png\", format=\"png\",bbox_inches='tight', pad_inches=0.2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf_report","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}